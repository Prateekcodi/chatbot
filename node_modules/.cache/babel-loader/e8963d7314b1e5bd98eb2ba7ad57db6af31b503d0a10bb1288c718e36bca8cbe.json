{"ast":null,"code":"// API service for frontend to communicate with backend\nconst BACKEND_URL = process.env.REACT_APP_BACKEND_URL || 'https://chatbot-1-u7m0.onrender.com';\nexport const sendMessageToGemini = async message => {\n  try {\n    const response = await fetch(`${BACKEND_URL}/api/ask`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        prompt: message\n      })\n    });\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n    const data = await response.json();\n\n    // Check if we have successful responses from any AI service\n    if (data.responses) {\n      // Find the first successful response (preferably Gemini)\n      const geminiResponse = data.responses.gemini;\n      const cohereResponse = data.responses.cohere;\n      const openrouterResponse = data.responses.openrouter;\n      const glmResponse = data.responses.glm;\n      const deepseekResponse = data.responses.deepseek;\n\n      // Prioritize Gemini, then Cohere, then OpenRouter, then GLM 4.5, then DeepSeek 3.1\n      let aiResponse = null;\n      if (geminiResponse && geminiResponse.success) {\n        aiResponse = geminiResponse;\n      } else if (cohereResponse && cohereResponse.success) {\n        aiResponse = cohereResponse;\n      } else if (openrouterResponse && openrouterResponse.success) {\n        aiResponse = openrouterResponse;\n      } else if (glmResponse && glmResponse.success) {\n        aiResponse = glmResponse;\n      } else if (deepseekResponse && deepseekResponse.success) {\n        aiResponse = deepseekResponse;\n      }\n      if (aiResponse && aiResponse.response) {\n        return {\n          success: true,\n          message: aiResponse.response,\n          data: data\n        };\n      }\n    }\n\n    // If no successful response found\n    return {\n      success: false,\n      message: 'No response from AI',\n      data: data\n    };\n  } catch (error) {\n    console.error('Error calling backend:', error);\n    return {\n      success: false,\n      message: 'Failed to get response from AI. Please try again.',\n      error: error\n    };\n  }\n};\n\n// Dedicated Chatbot function using the simpler endpoint\nexport const sendChatbotMessage = async message => {\n  try {\n    const response = await fetch(`${BACKEND_URL}/api/ask`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify({\n        prompt: message\n      })\n    });\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n    const data = await response.json();\n\n    // Check if we have successful responses from any AI service\n    if (data.responses) {\n      // Find the first successful response (preferably Gemini)\n      const geminiResponse = data.responses.gemini;\n      const cohereResponse = data.responses.cohere;\n      const openrouterResponse = data.responses.openrouter;\n\n      // Prioritize Gemini, then Cohere, then OpenRouter\n      let aiResponse = null;\n      if (geminiResponse && geminiResponse.success) {\n        aiResponse = geminiResponse;\n      } else if (cohereResponse && cohereResponse.success) {\n        aiResponse = cohereResponse;\n      } else if (openrouterResponse && openrouterResponse.success) {\n        aiResponse = openrouterResponse;\n      }\n      if (aiResponse && aiResponse.response) {\n        return {\n          success: true,\n          message: aiResponse.response,\n          data: data\n        };\n      }\n    }\n\n    // If no successful response found\n    return {\n      success: false,\n      message: 'No response from AI',\n      data: data\n    };\n  } catch (error) {\n    console.error('Error calling chatbot backend:', error);\n    return {\n      success: false,\n      message: 'Failed to get response from AI. Please try again.',\n      error: error\n    };\n  }\n};","map":{"version":3,"names":["BACKEND_URL","process","env","REACT_APP_BACKEND_URL","sendMessageToGemini","message","response","fetch","method","headers","body","JSON","stringify","prompt","ok","Error","status","data","json","responses","geminiResponse","gemini","cohereResponse","cohere","openrouterResponse","openrouter","glmResponse","glm","deepseekResponse","deepseek","aiResponse","success","error","console","sendChatbotMessage"],"sources":["/home/prateek/chatbot-app/src/services/api.ts"],"sourcesContent":["// API service for frontend to communicate with backend\nconst BACKEND_URL = process.env.REACT_APP_BACKEND_URL || 'https://chatbot-1-u7m0.onrender.com';\n\nexport interface ApiResponse {\n  success: boolean;\n  message: string;\n  data?: any;\n  error?: unknown;\n}\n\nexport const sendMessageToGemini = async (message: string): Promise<ApiResponse> => {\n  try {\n    const response = await fetch(`${BACKEND_URL}/api/ask`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({ prompt: message }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n\n    const data = await response.json();\n    \n    // Check if we have successful responses from any AI service\n    if (data.responses) {\n      // Find the first successful response (preferably Gemini)\n      const geminiResponse = data.responses.gemini;\n      const cohereResponse = data.responses.cohere;\n      const openrouterResponse = data.responses.openrouter;\n      const glmResponse = data.responses.glm;\n      const deepseekResponse = data.responses.deepseek;\n      \n      // Prioritize Gemini, then Cohere, then OpenRouter, then GLM 4.5, then DeepSeek 3.1\n      let aiResponse = null;\n      if (geminiResponse && geminiResponse.success) {\n        aiResponse = geminiResponse;\n      } else if (cohereResponse && cohereResponse.success) {\n        aiResponse = cohereResponse;\n      } else if (openrouterResponse && openrouterResponse.success) {\n        aiResponse = openrouterResponse;\n      } else if (glmResponse && glmResponse.success) {\n        aiResponse = glmResponse;\n      } else if (deepseekResponse && deepseekResponse.success) {\n        aiResponse = deepseekResponse;\n      }\n      \n      if (aiResponse && aiResponse.response) {\n        return {\n          success: true,\n          message: aiResponse.response,\n          data: data\n        };\n      }\n    }\n    \n    // If no successful response found\n    return {\n      success: false,\n      message: 'No response from AI',\n      data: data\n    };\n  } catch (error) {\n    console.error('Error calling backend:', error);\n    return {\n      success: false,\n      message: 'Failed to get response from AI. Please try again.',\n      error: error\n    };\n  }\n};\n\n// Dedicated Chatbot function using the simpler endpoint\nexport const sendChatbotMessage = async (message: string): Promise<ApiResponse> => {\n  try {\n    const response = await fetch(`${BACKEND_URL}/api/ask`, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({ prompt: message }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n\n    const data = await response.json();\n    \n    // Check if we have successful responses from any AI service\n    if (data.responses) {\n      // Find the first successful response (preferably Gemini)\n      const geminiResponse = data.responses.gemini;\n      const cohereResponse = data.responses.cohere;\n      const openrouterResponse = data.responses.openrouter;\n      \n      // Prioritize Gemini, then Cohere, then OpenRouter\n      let aiResponse = null;\n      if (geminiResponse && geminiResponse.success) {\n        aiResponse = geminiResponse;\n      } else if (cohereResponse && cohereResponse.success) {\n        aiResponse = cohereResponse;\n      } else if (openrouterResponse && openrouterResponse.success) {\n        aiResponse = openrouterResponse;\n      }\n      \n      if (aiResponse && aiResponse.response) {\n        return {\n          success: true,\n          message: aiResponse.response,\n          data: data\n        };\n      }\n    }\n    \n    // If no successful response found\n    return {\n      success: false,\n      message: 'No response from AI',\n      data: data\n    };\n  } catch (error) {\n    console.error('Error calling chatbot backend:', error);\n    return {\n      success: false,\n      message: 'Failed to get response from AI. Please try again.',\n      error: error\n    };\n  }\n};\n"],"mappings":"AAAA;AACA,MAAMA,WAAW,GAAGC,OAAO,CAACC,GAAG,CAACC,qBAAqB,IAAI,qCAAqC;AAS9F,OAAO,MAAMC,mBAAmB,GAAG,MAAOC,OAAe,IAA2B;EAClF,IAAI;IACF,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAGP,WAAW,UAAU,EAAE;MACrDQ,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE;MAClB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QAAEC,MAAM,EAAER;MAAQ,CAAC;IAC1C,CAAC,CAAC;IAEF,IAAI,CAACC,QAAQ,CAACQ,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAC,uBAAuBT,QAAQ,CAACU,MAAM,EAAE,CAAC;IAC3D;IAEA,MAAMC,IAAI,GAAG,MAAMX,QAAQ,CAACY,IAAI,CAAC,CAAC;;IAElC;IACA,IAAID,IAAI,CAACE,SAAS,EAAE;MAClB;MACA,MAAMC,cAAc,GAAGH,IAAI,CAACE,SAAS,CAACE,MAAM;MAC5C,MAAMC,cAAc,GAAGL,IAAI,CAACE,SAAS,CAACI,MAAM;MAC5C,MAAMC,kBAAkB,GAAGP,IAAI,CAACE,SAAS,CAACM,UAAU;MACpD,MAAMC,WAAW,GAAGT,IAAI,CAACE,SAAS,CAACQ,GAAG;MACtC,MAAMC,gBAAgB,GAAGX,IAAI,CAACE,SAAS,CAACU,QAAQ;;MAEhD;MACA,IAAIC,UAAU,GAAG,IAAI;MACrB,IAAIV,cAAc,IAAIA,cAAc,CAACW,OAAO,EAAE;QAC5CD,UAAU,GAAGV,cAAc;MAC7B,CAAC,MAAM,IAAIE,cAAc,IAAIA,cAAc,CAACS,OAAO,EAAE;QACnDD,UAAU,GAAGR,cAAc;MAC7B,CAAC,MAAM,IAAIE,kBAAkB,IAAIA,kBAAkB,CAACO,OAAO,EAAE;QAC3DD,UAAU,GAAGN,kBAAkB;MACjC,CAAC,MAAM,IAAIE,WAAW,IAAIA,WAAW,CAACK,OAAO,EAAE;QAC7CD,UAAU,GAAGJ,WAAW;MAC1B,CAAC,MAAM,IAAIE,gBAAgB,IAAIA,gBAAgB,CAACG,OAAO,EAAE;QACvDD,UAAU,GAAGF,gBAAgB;MAC/B;MAEA,IAAIE,UAAU,IAAIA,UAAU,CAACxB,QAAQ,EAAE;QACrC,OAAO;UACLyB,OAAO,EAAE,IAAI;UACb1B,OAAO,EAAEyB,UAAU,CAACxB,QAAQ;UAC5BW,IAAI,EAAEA;QACR,CAAC;MACH;IACF;;IAEA;IACA,OAAO;MACLc,OAAO,EAAE,KAAK;MACd1B,OAAO,EAAE,qBAAqB;MAC9BY,IAAI,EAAEA;IACR,CAAC;EACH,CAAC,CAAC,OAAOe,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,wBAAwB,EAAEA,KAAK,CAAC;IAC9C,OAAO;MACLD,OAAO,EAAE,KAAK;MACd1B,OAAO,EAAE,mDAAmD;MAC5D2B,KAAK,EAAEA;IACT,CAAC;EACH;AACF,CAAC;;AAED;AACA,OAAO,MAAME,kBAAkB,GAAG,MAAO7B,OAAe,IAA2B;EACjF,IAAI;IACF,MAAMC,QAAQ,GAAG,MAAMC,KAAK,CAAC,GAAGP,WAAW,UAAU,EAAE;MACrDQ,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE;MAClB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QAAEC,MAAM,EAAER;MAAQ,CAAC;IAC1C,CAAC,CAAC;IAEF,IAAI,CAACC,QAAQ,CAACQ,EAAE,EAAE;MAChB,MAAM,IAAIC,KAAK,CAAC,uBAAuBT,QAAQ,CAACU,MAAM,EAAE,CAAC;IAC3D;IAEA,MAAMC,IAAI,GAAG,MAAMX,QAAQ,CAACY,IAAI,CAAC,CAAC;;IAElC;IACA,IAAID,IAAI,CAACE,SAAS,EAAE;MAClB;MACA,MAAMC,cAAc,GAAGH,IAAI,CAACE,SAAS,CAACE,MAAM;MAC5C,MAAMC,cAAc,GAAGL,IAAI,CAACE,SAAS,CAACI,MAAM;MAC5C,MAAMC,kBAAkB,GAAGP,IAAI,CAACE,SAAS,CAACM,UAAU;;MAEpD;MACA,IAAIK,UAAU,GAAG,IAAI;MACrB,IAAIV,cAAc,IAAIA,cAAc,CAACW,OAAO,EAAE;QAC5CD,UAAU,GAAGV,cAAc;MAC7B,CAAC,MAAM,IAAIE,cAAc,IAAIA,cAAc,CAACS,OAAO,EAAE;QACnDD,UAAU,GAAGR,cAAc;MAC7B,CAAC,MAAM,IAAIE,kBAAkB,IAAIA,kBAAkB,CAACO,OAAO,EAAE;QAC3DD,UAAU,GAAGN,kBAAkB;MACjC;MAEA,IAAIM,UAAU,IAAIA,UAAU,CAACxB,QAAQ,EAAE;QACrC,OAAO;UACLyB,OAAO,EAAE,IAAI;UACb1B,OAAO,EAAEyB,UAAU,CAACxB,QAAQ;UAC5BW,IAAI,EAAEA;QACR,CAAC;MACH;IACF;;IAEA;IACA,OAAO;MACLc,OAAO,EAAE,KAAK;MACd1B,OAAO,EAAE,qBAAqB;MAC9BY,IAAI,EAAEA;IACR,CAAC;EACH,CAAC,CAAC,OAAOe,KAAK,EAAE;IACdC,OAAO,CAACD,KAAK,CAAC,gCAAgC,EAAEA,KAAK,CAAC;IACtD,OAAO;MACLD,OAAO,EAAE,KAAK;MACd1B,OAAO,EAAE,mDAAmD;MAC5D2B,KAAK,EAAEA;IACT,CAAC;EACH;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}